{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Method (Cluster Summary Based on Keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Set Enviorment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILESPATH = os.environ.get(\"FILESPATH\", \"/path/to/your/test/folder/\")\n",
    "CLUSTERS_DATAFRAME_NAME = os.environ.get(\"CLUSTERS_DATAFRAME_NAME\", \"df_cluster.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Load the Cluster DataFrame Containing the Documents and Cluster Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cluster DataFrame containing the documents and cluster assignments\n",
    "df_cluster_path = \"/home/tulipan16372/storage_NAS/Misc/Dani_Amaya/sentence-transformers/20240820_Matt_df_cluster.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "df_cluster = pd.read_csv(df_cluster_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "df_cluster.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Function to Extract the Top Keywords from Documents in a Given Cluster Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(documents, top_n=10):\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get the most important words for each document in the cluster\n",
    "    word_counts = Counter()\n",
    "    for doc_vector in X:\n",
    "        indices = doc_vector.nonzero()[1]\n",
    "        important_words = [feature_names[i] for i in indices]\n",
    "        word_counts.update(important_words)\n",
    "    \n",
    "    # Return the most common words in the cluster\n",
    "    return word_counts.most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Analyze and Display the Top 10 Keywords for a Specific Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which cluster number you want to analyze\n",
    "cluster_number = 0  # Example: Cluster 0\n",
    "\n",
    "# Get the documents belonging to the specified cluster, and remove NaN values\n",
    "documents_in_cluster = df_cluster[df_cluster['cluster'] == cluster_number]['documents'].dropna().tolist()\n",
    "\n",
    "# Extract the top 10 keywords in this cluster\n",
    "top_keywords = extract_keywords(documents_in_cluster, top_n=10)\n",
    "\n",
    "# Display the top keywords\n",
    "print(f\"Top 10 Keywords in Cluster {cluster_number}: {top_keywords}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Analyze and Display the Top Keywords for All Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and display the top keywords for all clusters\n",
    "for cluster in df_cluster['cluster'].unique():\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    \n",
    "    # Get the documents belonging to the specified cluster, and remove NaN values\n",
    "    documents_in_cluster = df_cluster[df_cluster['cluster'] == cluster]['documents'].dropna().tolist()\n",
    "    \n",
    "    # Extract the top 10 keywords in this cluster\n",
    "    top_keywords = extract_keywords(documents_in_cluster, top_n=10)\n",
    "    \n",
    "    # Display the top keywords\n",
    "    print(f\"Top 10 Keywords: {top_keywords}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Cluster Documents Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Set Enviorment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILESPATH = \"/home/tulipan16372/storage_NAS/Misc/Dani_Amaya/sentence-transformers/\"\n",
    "CLUSTERS_DATAFRAME_NAME = \"20240820_Matt_df_cluster.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Load the Cluster DataFrame Containing the Documents and Cluster Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_path = os.path.join(FILESPATH, CLUSTERS_DATAFRAME_NAME)\n",
    "df_cluster = pd.read_csv(df_cluster_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "df_cluster.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Initialize the Summarization Model from Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the summarization pipeline from Hugging Face\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Define Function to Summarize Documents for a Specific Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_cluster(documents, max_length=130, chunk_size=512):\n",
    "    # Combine all documents in the cluster into a single text\n",
    "    combined_text = ' '.join(documents)\n",
    "    \n",
    "    # Split the combined text into chunks that fit within the model's token limit\n",
    "    chunks = [combined_text[i:i + chunk_size] for i in range(0, len(combined_text), chunk_size)]\n",
    "    \n",
    "    # Summarize each chunk individually\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(chunk, max_length=max_length, min_length=30, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    # Combine all chunk summaries into a final summary\n",
    "    final_summary = ' '.join(summaries)\n",
    "    \n",
    "    return final_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Summarize and Display for a Specific Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which cluster number you want to analyze\n",
    "cluster_number = 0  # Example: Cluster 0\n",
    "\n",
    "# Get the documents belonging to the specified cluster, and remove NaN values\n",
    "documents_in_cluster = df_cluster[df_cluster['cluster'] == cluster_number]['documents'].dropna().tolist()\n",
    "\n",
    "# Summarize the documents in this cluster using the updated chunking method\n",
    "summary = summarize_cluster(documents_in_cluster)\n",
    "\n",
    "# Display the summary\n",
    "print(f\"Summary for Cluster {cluster_number}: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Summarize and Display for First Few Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summarize and display for the first few clusters (e.g., the first 5 clusters)\n",
    "# num_clusters_to_summarize = 5  # You can adjust this number to process more or fewer clusters\n",
    "\n",
    "# for i, cluster in enumerate(df_cluster['cluster'].unique()):\n",
    "#     if i >= num_clusters_to_summarize:\n",
    "#         break\n",
    "    \n",
    "#     print(f\"\\nCluster {cluster}:\")\n",
    "    \n",
    "#     # Get the documents belonging to the specified cluster, and remove NaN values\n",
    "#     documents_in_cluster = df_cluster[df_cluster['cluster'] == cluster]['documents'].dropna().tolist()\n",
    "    \n",
    "#     # Summarize the documents in this cluster using the updated chunking method\n",
    "#     summary = summarize_cluster(documents_in_cluster)\n",
    "    \n",
    "#     # Display the summary\n",
    "#     print(f\"Summary: {summary}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
